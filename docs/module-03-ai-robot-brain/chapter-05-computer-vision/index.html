<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-03-ai-robot-brain/chapter-05-computer-vision" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">chapter-05-computer-vision | Embodied Intelligence</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://Panaversity.github.io/SpecKit-Plus/img/matrix-bg.png"><meta data-rh="true" name="twitter:image" content="https://Panaversity.github.io/SpecKit-Plus/img/matrix-bg.png"><meta data-rh="true" property="og:url" content="https://Panaversity.github.io/SpecKit-Plus/docs/module-03-ai-robot-brain/chapter-05-computer-vision"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="ur"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="chapter-05-computer-vision | Embodied Intelligence"><meta data-rh="true" name="description" content="Introduction to Computer Vision in Robotics"><meta data-rh="true" property="og:description" content="Introduction to Computer Vision in Robotics"><link data-rh="true" rel="icon" href="https://github.com/MuhammedSuhaib.png"><link data-rh="true" rel="canonical" href="https://Panaversity.github.io/SpecKit-Plus/docs/module-03-ai-robot-brain/chapter-05-computer-vision"><link data-rh="true" rel="alternate" href="https://Panaversity.github.io/SpecKit-Plus/docs/module-03-ai-robot-brain/chapter-05-computer-vision" hreflang="en"><link data-rh="true" rel="alternate" href="https://Panaversity.github.io/SpecKit-Plus/ur/docs/module-03-ai-robot-brain/chapter-05-computer-vision" hreflang="ur"><link data-rh="true" rel="alternate" href="https://Panaversity.github.io/SpecKit-Plus/docs/module-03-ai-robot-brain/chapter-05-computer-vision" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"chapter-05-computer-vision","item":"https://Panaversity.github.io/SpecKit-Plus/docs/module-03-ai-robot-brain/chapter-05-computer-vision"}]}</script><script src="https://cdn.jsdelivr.net/npm/@openai/chatkit/dist/chatkit.umd.js" async></script><link rel="stylesheet" href="/SpecKit-Plus/assets/css/styles.adf69e15.css">
<script src="/SpecKit-Plus/assets/js/runtime~main.754b9477.js" defer="defer"></script>
<script src="/SpecKit-Plus/assets/js/main.e649bac2.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/SpecKit-Plus/img/matrix-bg.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_k978" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/SpecKit-Plus/"><div class="navbar__logo"><img src="/SpecKit-Plus/img/matrix-bg.png" alt="My Site Logo" class="themedComponent_beCX themedComponent--light_Hbs7"><img src="/SpecKit-Plus/img/matrix-bg.png" alt="My Site Logo" class="themedComponent_beCX themedComponent--dark_a98I"></div><b class="navbar__title text--truncate">Embodied Intelligence</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/SpecKit-Plus/docs/module-01-robotic-nervous-system/intro">Textbook</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/SpecKit-Plus/signin">Sign in</a><a class="navbar__item navbar__link navbar-signup-btn" href="/SpecKit-Plus/signup">Sign up</a><a href="https://github.com/MuhammedSuhaib/dockathon" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_Cy_U"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_lwka colorModeToggle_SVpo"><button class="clean-btn toggleButton_Mbg6 toggleButtonDisabled_dsJi" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_LX0_ lightToggleIcon_iZ7o"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_LX0_ darkToggleIcon_sbHe"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_LX0_ systemToggleIcon_rNLr"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_bxl4"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_CSSr"><div class="docsWrapper_b3o4"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_ngaE" type="button"></button><div class="docRoot_vnET"><aside class="theme-doc-sidebar-container docSidebarContainer_lkE3"><div class="sidebarViewport_l_GY"><div class="sidebar_rAVx"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_V6cO"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NYqt menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/SpecKit-Plus/docs/module-01-robotic-nervous-system/intro"><span title="Robotic Nervous System" class="categoryLinkLabel_ExjS">Robotic Nervous System</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NYqt menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/SpecKit-Plus/docs/module-02-digital-twin/intro"><span title="Digital Twin" class="categoryLinkLabel_ExjS">Digital Twin</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_NYqt menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/SpecKit-Plus/docs/module-03-ai-robot-brain/intro"><span title="AI Robot Brain" class="categoryLinkLabel_ExjS">AI Robot Brain</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/SpecKit-Plus/docs/module-03-ai-robot-brain/intro"><span title="intro" class="linkLabel_ElBB">intro</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/SpecKit-Plus/docs/module-03-ai-robot-brain/chapter-05-computer-vision"><span title="chapter-05-computer-vision" class="linkLabel_ElBB">chapter-05-computer-vision</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/SpecKit-Plus/docs/module-03-ai-robot-brain/chapter-06-navigation"><span title="chapter-06-navigation" class="linkLabel_ElBB">chapter-06-navigation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/SpecKit-Plus/docs/module-03-ai-robot-brain/chapter-07-isaac-sim"><span title="chapter-07-isaac-sim" class="linkLabel_ElBB">chapter-07-isaac-sim</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/SpecKit-Plus/docs/module-03-ai-robot-brain/chapter-08-isaac-ros"><span title="chapter-08-isaac-ros" class="linkLabel_ElBB">chapter-08-isaac-ros</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NYqt menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/SpecKit-Plus/docs/module-04-vision-language-action/intro"><span title="Vision Language Action" class="categoryLinkLabel_ExjS">Vision Language Action</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_WeUM"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_qoff"><div class="docItemContainer_phNv"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_q0fI" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/SpecKit-Plus/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_UB4j"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">AI Robot Brain</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">chapter-05-computer-vision</span></li></ul></nav><div class="tocCollapsible_Jjm_ theme-doc-toc-mobile tocMobile_KLro"><button type="button" class="clean-btn tocCollapsibleButton_ibvO">On this page</button></div><div class="theme-doc-markdown markdown"><div class="translate-button-container" style="margin-bottom:20px"><button style="padding:8px 16px;background-color:#00cc44;color:white;border:none;border-radius:4px;cursor:pointer">.Translate to Urdu</button></div>
<header><h1>Computer Vision - YOLO and Depth Cameras</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_BB1v" id="introduction-to-computer-vision-in-robotics">Introduction to Computer Vision in Robotics<a href="#introduction-to-computer-vision-in-robotics" class="hash-link" aria-label="Direct link to Introduction to Computer Vision in Robotics" title="Direct link to Introduction to Computer Vision in Robotics" translate="no">​</a></h2>
<p>Computer vision is a critical component of robotic perception systems, enabling robots to interpret and understand their visual environment. This chapter explores two fundamental technologies in computer vision: object detection using YOLO (You Only Look Once) and spatial perception using depth cameras.</p>
<h2 class="anchor anchorTargetStickyNavbar_BB1v" id="yolo-you-only-look-once-for-real-time-object-detection">YOLO (You Only Look Once) for Real-time Object Detection<a href="#yolo-you-only-look-once-for-real-time-object-detection" class="hash-link" aria-label="Direct link to YOLO (You Only Look Once) for Real-time Object Detection" title="Direct link to YOLO (You Only Look Once) for Real-time Object Detection" translate="no">​</a></h2>
<p>YOLO is a state-of-the-art real-time object detection system that revolutionized computer vision applications in robotics. Unlike traditional methods that process images in multiple passes, YOLO performs object detection in a single forward pass through a neural network, making it suitable for robotic applications where speed is critical.</p>
<h3 class="anchor anchorTargetStickyNavbar_BB1v" id="how-yolo-works">How YOLO Works<a href="#how-yolo-works" class="hash-link" aria-label="Direct link to How YOLO Works" title="Direct link to How YOLO Works" translate="no">​</a></h3>
<ol>
<li class=""><strong>Single-Pass Detection</strong>: YOLO divides the input image into a grid and simultaneously predicts bounding boxes and class probabilities for each grid cell</li>
<li class=""><strong>Speed vs. Accuracy</strong>: YOLO provides a good balance between detection speed and accuracy, making it ideal for robotic applications</li>
<li class=""><strong>Real-time Processing</strong>: Modern versions of YOLO (YOLOv5, YOLOv8) can achieve real-time performance on standard hardware</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_BB1v" id="yolo-in-robotic-applications">YOLO in Robotic Applications<a href="#yolo-in-robotic-applications" class="hash-link" aria-label="Direct link to YOLO in Robotic Applications" title="Direct link to YOLO in Robotic Applications" translate="no">​</a></h3>
<p>In robotics, YOLO is commonly used for:</p>
<ul>
<li class="">Object recognition and classification in the robot&#x27;s environment</li>
<li class="">Human detection for collaborative robotics</li>
<li class="">Obstacle detection for navigation systems</li>
<li class="">Quality inspection in manufacturing robotics</li>
<li class="">Agricultural robotics for crop monitoring and harvesting</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_BB1v" id="depth-cameras-for-spatial-perception">Depth Cameras for Spatial Perception<a href="#depth-cameras-for-spatial-perception" class="hash-link" aria-label="Direct link to Depth Cameras for Spatial Perception" title="Direct link to Depth Cameras for Spatial Perception" translate="no">​</a></h2>
<p>Depth cameras provide crucial 3D spatial information that is essential for robotic navigation, manipulation, and interaction with the environment. These cameras capture not only color information but also depth data for each pixel in the image.</p>
<h3 class="anchor anchorTargetStickyNavbar_BB1v" id="types-of-depth-cameras">Types of Depth Cameras<a href="#types-of-depth-cameras" class="hash-link" aria-label="Direct link to Types of Depth Cameras" title="Direct link to Types of Depth Cameras" translate="no">​</a></h3>
<ol>
<li class=""><strong>Stereo Vision Cameras</strong>: Use two or more cameras to capture images from slightly different angles to calculate depth based on parallax</li>
<li class=""><strong>Time-of-Flight (ToF) Cameras</strong>: Measure the time it takes for light to travel to objects and back to determine distance</li>
<li class=""><strong>Structured Light Cameras</strong>: Project a known light pattern and measure how it deforms when hitting surfaces to calculate depth</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_BB1v" id="depth-camera-applications-in-robotics">Depth Camera Applications in Robotics<a href="#depth-camera-applications-in-robotics" class="hash-link" aria-label="Direct link to Depth Camera Applications in Robotics" title="Direct link to Depth Camera Applications in Robotics" translate="no">​</a></h3>
<p>Depth cameras enable several key robotic capabilities:</p>
<ul>
<li class=""><strong>3D Mapping</strong>: Creating detailed spatial maps of the environment</li>
<li class=""><strong>Obstacle Avoidance</strong>: Detecting and avoiding obstacles in the path of mobile robots</li>
<li class=""><strong>Object Manipulation</strong>: Providing 3D information necessary for precise robotic manipulation tasks</li>
<li class=""><strong>SLAM Integration</strong>: Feeding depth data into Simultaneous Localization and Mapping systems</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_BB1v" id="integration-with-robotic-systems">Integration with Robotic Systems<a href="#integration-with-robotic-systems" class="hash-link" aria-label="Direct link to Integration with Robotic Systems" title="Direct link to Integration with Robotic Systems" translate="no">​</a></h2>
<p>Modern robotic systems often integrate YOLO and depth camera technologies to create comprehensive perception capabilities:</p>
<h3 class="anchor anchorTargetStickyNavbar_BB1v" id="object-detection-with-depth-information">Object Detection with Depth Information<a href="#object-detection-with-depth-information" class="hash-link" aria-label="Direct link to Object Detection with Depth Information" title="Direct link to Object Detection with Depth Information" translate="no">​</a></h3>
<ul>
<li class="">Combining YOLO object detection with depth data to understand not just what objects are present, but also their 3D positions</li>
<li class="">Enabling robots to grasp objects at known distances or avoid obstacles based on both recognition and spatial information</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_BB1v" id="ros-integration">ROS Integration<a href="#ros-integration" class="hash-link" aria-label="Direct link to ROS Integration" title="Direct link to ROS Integration" translate="no">​</a></h3>
<ul>
<li class="">Both YOLO and depth cameras can be integrated with Robot Operating System (ROS) using standard packages</li>
<li class="">YOLO implementations are available through ROS packages like darknet_ros</li>
<li class="">Depth cameras typically provide depth images through ROS sensor_msgs/Image topics with appropriate calibration parameters</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_BB1v" id="best-practices-for-implementation">Best Practices for Implementation<a href="#best-practices-for-implementation" class="hash-link" aria-label="Direct link to Best Practices for Implementation" title="Direct link to Best Practices for Implementation" translate="no">​</a></h2>
<ol>
<li class=""><strong>Lighting Considerations</strong>: Different depth camera technologies perform differently under varying lighting conditions</li>
<li class=""><strong>Computational Requirements</strong>: Ensure sufficient computing power for real-time YOLO processing and depth data handling</li>
<li class=""><strong>Calibration</strong>: Properly calibrate both YOLO models (for accuracy) and depth cameras (for spatial accuracy)</li>
<li class=""><strong>Data Fusion</strong>: Implement effective fusion techniques to combine YOLO detection results with depth information</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_BB1v" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary" translate="no">​</a></h2>
<p>Computer vision combining YOLO object detection with depth camera spatial information creates powerful perception capabilities for robots. These technologies enable robots to understand both what objects are in their environment and where those objects are located in 3D space, which is essential for navigation, manipulation, and interaction tasks.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_LFcd"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-03-ai-robot-brain/chapter-05-computer-vision.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_cm6n" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_o2CG"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/SpecKit-Plus/docs/module-03-ai-robot-brain/intro"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">intro</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/SpecKit-Plus/docs/module-03-ai-robot-brain/chapter-06-navigation"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">chapter-06-navigation</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_Odgc thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction-to-computer-vision-in-robotics" class="table-of-contents__link toc-highlight">Introduction to Computer Vision in Robotics</a></li><li><a href="#yolo-you-only-look-once-for-real-time-object-detection" class="table-of-contents__link toc-highlight">YOLO (You Only Look Once) for Real-time Object Detection</a><ul><li><a href="#how-yolo-works" class="table-of-contents__link toc-highlight">How YOLO Works</a></li><li><a href="#yolo-in-robotic-applications" class="table-of-contents__link toc-highlight">YOLO in Robotic Applications</a></li></ul></li><li><a href="#depth-cameras-for-spatial-perception" class="table-of-contents__link toc-highlight">Depth Cameras for Spatial Perception</a><ul><li><a href="#types-of-depth-cameras" class="table-of-contents__link toc-highlight">Types of Depth Cameras</a></li><li><a href="#depth-camera-applications-in-robotics" class="table-of-contents__link toc-highlight">Depth Camera Applications in Robotics</a></li></ul></li><li><a href="#integration-with-robotic-systems" class="table-of-contents__link toc-highlight">Integration with Robotic Systems</a><ul><li><a href="#object-detection-with-depth-information" class="table-of-contents__link toc-highlight">Object Detection with Depth Information</a></li><li><a href="#ros-integration" class="table-of-contents__link toc-highlight">ROS Integration</a></li></ul></li><li><a href="#best-practices-for-implementation" class="table-of-contents__link toc-highlight">Best Practices for Implementation</a></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Textbook</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/SpecKit-Plus/docs/module-01-robotic-nervous-system/intro">Robotic Nervous System</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://x.com/cuhaib1" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_Cy_U"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/MuhammedSuhaib/dockathon" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_Cy_U"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Panaversity. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>